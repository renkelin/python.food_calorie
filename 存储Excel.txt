from gevent import monkey
monkey.patch_all()
from gevent.queue import Queue

import requests
import gevent
from bs4 import BeautifulSoup
import openpyxl

# 实例化一个工作簿
wb = openpyxl.Workbook()
# 创建工作表
sheet = wb.active
# 获取工作活动表
sheet.title = 'boohee.com'
# 将工作表重命名
column_name = ['食物名', '食物详情链接', '食物热量']
sheet.append(column_name)

# 创建work的Q队列
work = Queue()

for x in range(1, 4):
    for y in range(1, 4):
        start_url = 'https://www.boohee.com/food/group/{}?page={}'.format(x, y)
        # 把构造的url使用put_nowait()放入/添加到work队列中
        work.put_nowait(start_url)

for x in range(1, 4):
    start_url = 'https://www.boohee.com/food/view_menu?page={}'.format(x)
    work.put_nowait(start_url)
    # print(start_url)

def boohee_spider():
    headers = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.164 Safari/537.36'
    }
    while not work.empty():
        url = work.get_nowait()  # 使用get_nowait()方法将请求头url从队列中提取出来
        res = requests.get(url=url, headers=headers)
        if res.status_code == 200:

            bs_res = BeautifulSoup(res.text, 'html.parser')
            datas = bs_res.find_all('li', class_='item clearfix')
            for data in datas:
                # 食物名称
                food_name = data.find_all('a')[1]['title']
                # 食物详情链接
                food_url = 'https://www.boohee.com' + data.find_all('a')[1]['href']
                # 食物热量
                food_calorie = data.find('p').text
                sheet.append([food_name, food_url, food_calorie])
            wb.save('food_hot.xlsx')
            wb.close()
        else:
            print("请求失败")

boohee_spider()

task_list = []
for i in range(1, 6):
    task = gevent.spawn(boohee_spider)  # 使用gevent.spawn()函数创建执行的boohee_spider()爬虫任务
    task_list.append(task)

# 使用gevent.join_all()方法,启动协程,执行任务列表task_list
gevent.joinall(task_list)